{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from feature_extraction import Blob, Words, Exclude, WordCount, POS, Readable\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, SelectFromModel\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "\n",
    "from calzone import describe, lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('processed_datascience1.csv.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  id  |  subreddit  |                                                               title                                                               |ups|                                                                    url                                                                     |created_utc|\n",
      "|------|-------------|-----------------------------------------------------------------------------------------------------------------------------------|--:|--------------------------------------------------------------------------------------------------------------------------------------------|----------:|\n",
      "|84zvji|r/datascience|Academic data science training programs: crowd-sourced list                                                                        |  2|https://www.reddit.com/r/datascience/comments/84zvji/academic_data_science_training_programs/                                               | 1521243666|\n",
      "|84zpza|r/datascience|How to build killer Datasets, and the 6 biggest mistakes to avoid.                                                                 |  2|https://medium.com/@juliendespois/stop-feeding-garbage-to-your-model-the-6-biggest-mistakes-with-datasets-and-how-to-avoid-them-3cb7532ad3b7| 1521242108|\n",
      "|84xz2e|r/datascience|FPGA-embedded ML                                                                                                                   |  2|https://www.reddit.com/r/datascience/comments/84xz2e/fpgaembedded_ml/                                                                       | 1521227458|\n",
      "|84xfmv|r/datascience|Creating dendrogram using MLlib Kmeans data (pyspark) - help                                                                       |  2|https://www.reddit.com/r/datascience/comments/84xfmv/creating_dendrogram_using_mllib_kmeans_data/                                           | 1521223335|\n",
      "|84xcbl|r/datascience|what is your personal list of the 10 most important _fundamental_ , canonical data science problems that a beginner should address?|101|https://www.reddit.com/r/datascience/comments/84xcbl/what_is_your_personal_list_of_the_10_most/                                             | 1521222598|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytablewriter\n",
    "writer = pytablewriter.MarkdownTableWriter()\n",
    "writer.from_dataframe(data.head())\n",
    "writer.write_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, subreddit, title, ups, url, created_utc]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['ups'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the grab_posts module if you want to grab posts from specific subreddits and time-frames\n",
    "# To retrieve your own posts requires a reddit developer account\n",
    "#from calzone import grab_posts\n",
    "#data = grab_posts(sub='todayilearned', start='01/24/2018', end='02/05/2018', number=30000, verbose=True)\n",
    "\n",
    "# Data clean - \n",
    "# 1. remove '/' character\n",
    "# 2. lowercase all letters\n",
    "# 3. lemmatize all words - change words to their root words, ie 'wanted -> want'\n",
    "\n",
    "data['title'] = lemmatize(data)\n",
    "\n",
    "## Optional: Throw out outliers by including rows with Z-Scores less than 2.5 and greater than -2.5\n",
    "data['z_scores'] = np.abs((data.ups-data.ups.mean())/data.ups.std())\n",
    "data = data[data['z_scores']<= 2.5]\n",
    "\n",
    "## Optional: Log transformation of up-votes\n",
    "data['log_ups'] = np.log1p(data['ups'])\n",
    "\n",
    "# Create Label column defining whether or not the article's votes exceed the average vote for the subreddit\n",
    "data['gtavg'] = data.log_ups > data.log_ups.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa0fd8eec>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.ups.hist(grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6579, 6)\n"
     ]
    }
   ],
   "source": [
    "i = data[data.ups < 7.7]\n",
    "j = data[data.ups >= 7.7]\n",
    "print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Titles in Dataset: 9271\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Characters</th>\n",
       "      <th>Words</th>\n",
       "      <th>Noun_Phrases</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Consonants</th>\n",
       "      <th>Vowels</th>\n",
       "      <th>Kincaid</th>\n",
       "      <th>Flesch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>1.474275</td>\n",
       "      <td>16</td>\n",
       "      <td>0.196472</td>\n",
       "      <td>0.074312</td>\n",
       "      <td>7.719124</td>\n",
       "      <td>39</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Success</th>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>1.530089</td>\n",
       "      <td>17</td>\n",
       "      <td>0.213003</td>\n",
       "      <td>0.086901</td>\n",
       "      <td>20.521545</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Failure</th>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>1.451436</td>\n",
       "      <td>16</td>\n",
       "      <td>0.189709</td>\n",
       "      <td>0.069161</td>\n",
       "      <td>2.480620</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Characters  Words  Noun_Phrases  Syllables  Subjectivity  Polarity  \\\n",
       "All              58     10      1.474275         16      0.196472  0.074312   \n",
       "Success          60     11      1.530089         17      0.213003  0.086901   \n",
       "Failure          57     10      1.451436         16      0.189709  0.069161   \n",
       "\n",
       "             Votes  Consonants  Vowels  Kincaid  Flesch  \n",
       "All       7.719124          39      18        8      47  \n",
       "Success  20.521545          41      19        8      48  \n",
       "Failure   2.480620          38      18        8      46  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Total Number of Titles in Dataset:', len(data['title']))\n",
    "results = describe(data) # calzone function to extract title attributes\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Characters|Words|Noun_Phrases|Syllables|Subjectivity|Polarity|Votes |Consonants|Vowels|Kincaid|Flesch|\n",
      "|---------:|----:|-----------:|--------:|-----------:|-------:|-----:|---------:|-----:|------:|-----:|\n",
      "|        58|   10|       1.474|       16|      0.1965| 0.07431| 7.719|        39|    18|      8|    47|\n",
      "|        60|   11|       1.530|       17|      0.2130| 0.08690|20.522|        41|    19|      8|    48|\n",
      "|        57|   10|       1.451|       16|      0.1897| 0.06916| 2.481|        38|    18|      8|    46|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytablewriter\n",
    "writer = pytablewriter.MarkdownTableWriter()\n",
    "writer.from_dataframe(results)\n",
    "writer.write_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       |Characters|Words|Noun_Phrases|Syllables|Subjectivity|Polarity|Votes |Consonants|Vowels|Kincaid|Flesch|\n",
    "|------:|---------:|----:|-----------:|--------:|-----------:|-------:|-----:|---------:|-----:|------:|-----:|\n",
    "|All    |        58|   10|       1.474|       16|      0.1965| 0.07431| 7.719|        39|    18|      8|    47|\n",
    "|Success|        60|   11|       1.530|       17|      0.2130| 0.08690|20.522|        41|    19|      8|    48|\n",
    "|Failure|        57|   10|       1.451|       16|      0.1897| 0.06916| 2.481|        38|    18|      8|    46|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE VOTES:  7.7\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data.title, \n",
    "                                                    data.gtavg, \n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=25)\n",
    "\n",
    "print('AVERAGE VOTES: ', '{:03.1f}'.format(data.ups.mean()))\n",
    "\n",
    "# 1. Sklearn has a pipeline Class that directs the flow of model creation; \n",
    "# below the pipeline corals the features into the Random Forest classifer.\n",
    "# 2. Within the pipeline is a sklearn Class called FeatureUnion.  \n",
    "# 3. Feature Union allows for the joining of multiple features into a single vector\n",
    "# 4. Within the feature union is a transformer list,\n",
    "# containingclasses that performed the functions described above\n",
    "# 5. The final pipeline item is the declaration of a classifier,\n",
    "# that the combined feature vector will be inserted into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            ('pipe', Pipeline([\n",
    "                ('inner', FeatureUnion(\n",
    "                    transformer_list=[\n",
    "                        ('pos', POS()),\n",
    "\n",
    "                        ('read', Readable()),\n",
    "\n",
    "                        ('words', Words()),\n",
    "\n",
    "                        ('blob', Pipeline([\n",
    "                            ('all', Blob()),\n",
    "                            ('minmax', MinMaxScaler()),\n",
    "                        ])),\n",
    "                ])),\n",
    "                ('select', SelectFromModel(ExtraTreesClassifier()))\n",
    "\n",
    "            ])),\n",
    "\n",
    "            ('title', Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', \n",
    "                                          ngram_range=(1,3), sublinear_tf=True,\n",
    "                                          strip_accents='unicode', stop_words='english')),\n",
    "                ('svd', TruncatedSVD(n_components=120)),\n",
    "                ('normalize', MinMaxScaler(copy=False)),\n",
    "                ('selector', SelectPercentile(f_classif, percentile=10))\n",
    "            ])),\n",
    "\n",
    "\n",
    "            ])),\n",
    "    ('clf', RandomForestClassifier(n_estimators=190, n_jobs=-1, max_depth=5, max_features='log2',\n",
    "                                  min_samples_leaf=1, min_samples_split=77)),\n",
    "        ])\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(train_X, train_y)\n",
    "\n",
    "# Predict Test Set\n",
    "y_pred = pipeline.predict(test_X)\n",
    "\n",
    "# Save our model\n",
    "joblib.dump(pipeline, 'datascience.xz', compress=('xz', 9))\n",
    "\n",
    "# Test it out\n",
    "pipeline.predict(pd.Series(['A tutorial on my machine-learning workflow \\\n",
    "                            for predicting whether or not this post will be popular']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.9%\n",
      "F1 Score: 0.525\n",
      "CV Scores:  [0.57142857 0.57923129 0.54888739 0.55563048 0.54079568]\n"
     ]
    }
   ],
   "source": [
    "# Measure prediction Accuracy and F1 Score\n",
    "accuracy = accuracy_score(y_pred=y_pred, y_true=test_y)\n",
    "print('Accuracy: {:03.1f}%'.format(accuracy * 100))\n",
    "\n",
    "print('F1 Score: {:.3f}'.format(f1_score(test_y, y_pred)))\n",
    "\n",
    "# Cross Validate prediction Score\n",
    "print('CV Scores: ', cross_val_score(pipeline, train_X, train_y, cv=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
