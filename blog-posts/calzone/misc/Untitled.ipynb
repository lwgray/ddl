{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from feature_extraction import Blob, Words, Exclude, WordCount, POS, Readable\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, SelectFromModel\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "\n",
    "from calzone import describe, lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('processed_datascience1.csv.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  id  |  subreddit  |                                                               title                                                               |ups|                                                                    url                                                                     |created_utc|\n",
      "|------|-------------|-----------------------------------------------------------------------------------------------------------------------------------|--:|--------------------------------------------------------------------------------------------------------------------------------------------|----------:|\n",
      "|84zvji|r/datascience|Academic data science training programs: crowd-sourced list                                                                        |  2|https://www.reddit.com/r/datascience/comments/84zvji/academic_data_science_training_programs/                                               | 1521243666|\n",
      "|84zpza|r/datascience|How to build killer Datasets, and the 6 biggest mistakes to avoid.                                                                 |  2|https://medium.com/@juliendespois/stop-feeding-garbage-to-your-model-the-6-biggest-mistakes-with-datasets-and-how-to-avoid-them-3cb7532ad3b7| 1521242108|\n",
      "|84xz2e|r/datascience|FPGA-embedded ML                                                                                                                   |  2|https://www.reddit.com/r/datascience/comments/84xz2e/fpgaembedded_ml/                                                                       | 1521227458|\n",
      "|84xfmv|r/datascience|Creating dendrogram using MLlib Kmeans data (pyspark) - help                                                                       |  2|https://www.reddit.com/r/datascience/comments/84xfmv/creating_dendrogram_using_mllib_kmeans_data/                                           | 1521223335|\n",
      "|84xcbl|r/datascience|what is your personal list of the 10 most important _fundamental_ , canonical data science problems that a beginner should address?|101|https://www.reddit.com/r/datascience/comments/84xcbl/what_is_your_personal_list_of_the_10_most/                                             | 1521222598|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytablewriter\n",
    "writer = pytablewriter.MarkdownTableWriter()\n",
    "writer.from_dataframe(data.head())\n",
    "writer.write_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, subreddit, title, ups, url, created_utc]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['ups'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the grab_posts module if you want to grab posts from specific subreddits and time-frames\n",
    "# To retrieve your own posts requires a reddit developer account\n",
    "#from calzone import grab_posts\n",
    "#data = grab_posts(sub='todayilearned', start='01/24/2018', end='02/05/2018', number=30000, verbose=True)\n",
    "\n",
    "# Data clean - \n",
    "# 1. remove '/' character\n",
    "# 2. lowercase all letters\n",
    "# 3. lemmatize all words - change words to their root words, ie 'wanted -> want'\n",
    "\n",
    "data['title'] = lemmatize(data)\n",
    "\n",
    "## Optional: Throw out outliers by including rows with Z-Scores less than 2.5 and greater than -2.5\n",
    "data['z_scores'] = np.abs((data.ups-data.ups.mean())/data.ups.std())\n",
    "data = data[data['z_scores']<= 2.5]\n",
    "\n",
    "## Optional: Log transformation of up-votes\n",
    "data['log_ups'] = np.log1p(data['ups'])\n",
    "\n",
    "# Create Label column defining whether or not the article's votes exceed the average vote for the subreddit\n",
    "data['gtavg'] = data.log_ups > data.log_ups.mean()\n",
    "booldict = {True: 'Popular', False: 'Unpopular'}\n",
    "data['gtavg'] = data.gtavg.map(booldict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa955f78c>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.ups.hist(grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6579, 9)\n",
      "(2692, 9)\n"
     ]
    }
   ],
   "source": [
    "i = data[data.ups < 7.7]\n",
    "j = data[data.ups >= 7.7]\n",
    "print(i.shape)\n",
    "print(j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Titles in Dataset: 9271\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Characters</th>\n",
       "      <th>Words</th>\n",
       "      <th>Noun_Phrases</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Consonants</th>\n",
       "      <th>Vowels</th>\n",
       "      <th>Kincaid</th>\n",
       "      <th>Flesch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>1.474275</td>\n",
       "      <td>16</td>\n",
       "      <td>0.196472</td>\n",
       "      <td>0.074312</td>\n",
       "      <td>7.719124</td>\n",
       "      <td>39</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Success</th>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>1.530089</td>\n",
       "      <td>17</td>\n",
       "      <td>0.213003</td>\n",
       "      <td>0.086901</td>\n",
       "      <td>20.521545</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Failure</th>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>1.451436</td>\n",
       "      <td>16</td>\n",
       "      <td>0.189709</td>\n",
       "      <td>0.069161</td>\n",
       "      <td>2.480620</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Characters  Words  Noun_Phrases  Syllables  Subjectivity  Polarity  \\\n",
       "All              58     10      1.474275         16      0.196472  0.074312   \n",
       "Success          60     11      1.530089         17      0.213003  0.086901   \n",
       "Failure          57     10      1.451436         16      0.189709  0.069161   \n",
       "\n",
       "             Votes  Consonants  Vowels  Kincaid  Flesch  \n",
       "All       7.719124          39      18        8      47  \n",
       "Success  20.521545          41      19        8      48  \n",
       "Failure   2.480620          38      18        8      46  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Total Number of Titles in Dataset:', len(data['title']))\n",
    "results = describe(data) # calzone function to extract title attributes\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Characters|Words|Noun_Phrases|Syllables|Subjectivity|Polarity|Votes |Consonants|Vowels|Kincaid|Flesch|\n",
      "|---------:|----:|-----------:|--------:|-----------:|-------:|-----:|---------:|-----:|------:|-----:|\n",
      "|        58|   10|       1.474|       16|      0.1965| 0.07431| 7.719|        39|    18|      8|    47|\n",
      "|        60|   11|       1.530|       17|      0.2130| 0.08690|20.522|        41|    19|      8|    48|\n",
      "|        57|   10|       1.451|       16|      0.1897| 0.06916| 2.481|        38|    18|      8|    46|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytablewriter\n",
    "writer = pytablewriter.MarkdownTableWriter()\n",
    "writer.from_dataframe(results)\n",
    "writer.write_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       |Characters|Words|Noun_Phrases|Syllables|Subjectivity|Polarity|Votes |Consonants|Vowels|Kincaid|Flesch|\n",
    "|------:|---------:|----:|-----------:|--------:|-----------:|-------:|-----:|---------:|-----:|------:|-----:|\n",
    "|All    |        58|   10|       1.474|       16|      0.1965| 0.07431| 7.719|        39|    18|      8|    47|\n",
    "|Success|        60|   11|       1.530|       17|      0.2130| 0.08690|20.522|        41|    19|      8|    48|\n",
    "|Failure|        57|   10|       1.451|       16|      0.1897| 0.06916| 2.481|        38|    18|      8|    46|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE VOTES:  7.7\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data.title, \n",
    "                                                    data.gtavg, \n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=25)\n",
    "\n",
    "print('AVERAGE VOTES: ', '{:03.1f}'.format(data.ups.mean()))\n",
    "\n",
    "# 1. Sklearn has a pipeline Class that directs the flow of model creation; \n",
    "# below the pipeline corals the features into the Random Forest classifer.\n",
    "# 2. Within the pipeline is a sklearn Class called FeatureUnion.  \n",
    "# 3. Feature Union allows for the joining of multiple features into a single vector\n",
    "# 4. Within the feature union is a transformer list,\n",
    "# containingclasses that performed the functions described above\n",
    "# 5. The final pipeline item is the declaration of a classifier,\n",
    "# that the combined feature vector will be inserted into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Popular'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            ('pipe', Pipeline([\n",
    "                ('inner', FeatureUnion(\n",
    "                    transformer_list=[\n",
    "                        ('pos', POS()),\n",
    "\n",
    "                        ('read', Readable()),\n",
    "\n",
    "                        ('words', Words()),\n",
    "\n",
    "                        ('blob', Pipeline([\n",
    "                            ('all', Blob()),\n",
    "                            ('minmax', MinMaxScaler()),\n",
    "                        ])),\n",
    "                ])),\n",
    "                ('select', SelectFromModel(ExtraTreesClassifier()))\n",
    "\n",
    "            ])),\n",
    "\n",
    "            ('title', Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', \n",
    "                                          ngram_range=(1,3), sublinear_tf=True,\n",
    "                                          strip_accents='unicode', stop_words='english')),\n",
    "                ('svd', TruncatedSVD(n_components=120)),\n",
    "                ('normalize', MinMaxScaler(copy=False)),\n",
    "                ('selector', SelectPercentile(f_classif, percentile=10))\n",
    "            ])),\n",
    "\n",
    "\n",
    "            ])),\n",
    "    ('clf', RandomForestClassifier(n_estimators=190, n_jobs=-1, max_depth=5, max_features='log2',\n",
    "                                  min_samples_leaf=1, min_samples_split=77)),\n",
    "        ])\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(train_X, train_y)\n",
    "\n",
    "# Predict Test Set\n",
    "y_pred = pipeline.predict(test_X)\n",
    "\n",
    "# Save our model\n",
    "joblib.dump(pipeline, 'datascience.xz', compress=('xz', 9))\n",
    "\n",
    "# Test it out\n",
    "pipeline.predict(pd.Series(['A tutorial on my machine-learning workflow \\\n",
    "                            for predicting whether or not this post will be popular']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure prediction Accuracy and F1 Score\n",
    "accuracy = accuracy_score(y_pred=y_pred, y_true=test_y)\n",
    "print('Accuracy: {:03.1f}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwgray/anaconda3/envs/ddl/lib/python3.6/site-packages/sklearn/metrics/classification.py:1030: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if pos_label not in present_labels:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label: array(['Popular', 'Unpopular'], dtype='<U9')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-63cbb022b5e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F1 Score: {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ddl/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ddl/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ddl/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                     raise ValueError(\"pos_label=%r is not a valid label: %r\" %\n\u001b[0;32m-> 1036\u001b[0;31m                                      (pos_label, present_labels))\n\u001b[0m\u001b[1;32m   1037\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pos_label=1 is not a valid label: array(['Popular', 'Unpopular'], dtype='<U9')"
     ]
    }
   ],
   "source": [
    "print('F1 Score: {:.3f}'.format(f1_score(test_y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores:  [0.56671159 0.5799056  0.56035064 0.55360755 0.55967633]\n"
     ]
    }
   ],
   "source": [
    "# Cross Validate prediction Score\n",
    "print('CV Scores: ', cross_val_score(pipeline, train_X, train_y, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
